{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"hSRe-mCX8RdE","executionInfo":{"status":"ok","timestamp":1652109509752,"user_tz":300,"elapsed":7083,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["import io\n","import pandas as pd\n","import numpy as np\n","import scipy as sci\n","\n","from sklearn.preprocessing import MinMaxScaler # found in the scikit-learn package\n","from numpy import loadtxt\n","#from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","#from keras.optimizers import SGD\n","#from keras.optimizers import Adam\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","##from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"vDwlafar8jeJ","outputId":"3d74c15c-4ab3-462e-a9fc-2a052627d6a3","executionInfo":{"status":"error","timestamp":1652109510674,"user_tz":300,"elapsed":925,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-85ce4694c9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read the CSV file and store it as a pandas DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m#Initialize the index at 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data-ts.csv'"]}],"source":["# The path where the CSV file is located\n","# Use your own path\n","path = \"data-ts.csv\"\n","\n","# Read the CSV file and store it as a pandas DataFrame\n","df = pd.read_csv(path)\n","\n","df.index = df.index + 1 #Initialize the index at 1\n","\n","# Lag the data frame\n","data = pd.concat([df.shift(1), df.shift(2), df.shift(3), df], axis=1)\n","data.columns = ['x1','x2', 'x3', 'y']\n","data = data.iloc[4:,]\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0NbetIXFiDta","executionInfo":{"status":"aborted","timestamp":1652109510667,"user_tz":300,"elapsed":6,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Pick 80% of the data but keeps the original sequence (R)\n","train = data[:int(data.shape[0]*0.8)]\n","test = data[int(data.shape[0]*0.8):]\n","\n","# Clean data in case of missing data\n","data = data.dropna()\n","train = train.dropna()\n","test = test.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n9OaJTbn-ith","executionInfo":{"status":"aborted","timestamp":1652109510668,"user_tz":300,"elapsed":6,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Calculate parameter for scaling back the outcome variable, both for the prediction and the actual values\n","ytrain_min = float(train.min()['y'])\n","ytrain_max = float(train.max()['y'])\n","ytrain_range = ytrain_max - ytrain_min\n","\n","ytest_min = float(test.min()['y'])\n","ytest_max = float(test.max()['y'])\n","ytest_range = ytest_max - ytest_min"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ignooxyc-itj","executionInfo":{"status":"aborted","timestamp":1652109510669,"user_tz":300,"elapsed":7,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Normalize the data frame\n","def scale(data):\n","    scaled_data = data.copy()\n","    for column in data.columns: \n","      scaled_data[column] = (data[column] - data[column].min()) / (data[column].max() - data[column].min())\n","    return scaled_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bIQ28hOc-itk","executionInfo":{"status":"aborted","timestamp":1652109510669,"user_tz":300,"elapsed":7,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Scale back the data frame\n","def scale_back(data, data_min, data_range):\n","    data_ = data.copy()\n","    data_.head()\n","    for column in data_.columns: \n","        data_[column] = (data_range) * data_[column] + data_min\n","    return data_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uyh9WTAEqbqE","executionInfo":{"status":"aborted","timestamp":1652109510670,"user_tz":300,"elapsed":8,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Normalize the train data in the range of 0-1\n","train_ = scale(train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jnkH7aIq7fF","executionInfo":{"status":"aborted","timestamp":1652109510671,"user_tz":300,"elapsed":8,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Normalize the test data in the range of 0-1\n","test_ = scale(test)\n","test_\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3vjqdLfdavr","executionInfo":{"status":"aborted","timestamp":1652109510672,"user_tz":300,"elapsed":9,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Separate the input (x) and output (y)\n","n = train_.columns                                    #column labels\n","xtrain = train_.filter(items = ['x1','x2','x3'])  #input of the training set\n","ytrain = train_.filter(items = ['y'])                    #output of the training set\n","\n","xtest = test_.filter(items = ['x1','x2','x3'])  #input of the test set\n","ytest = test_.filter(items = ['y'])                    #output of the test set\n","\n","ytest.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g9ftQmTt-itt","executionInfo":{"status":"aborted","timestamp":1652109510672,"user_tz":300,"elapsed":9,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["# Train a neural network model\n","# https://www.tensorflow.org/api_docs/python/tf/keras/activations\n","model = Sequential()\n","\n","# First add a layer with 3 neurons for 3 input variables (3 lags)\n","# and the RELU activation function\n","model.add(Dense(3, input_dim=3, activation='relu'))\n","\n","# Then add a hidden layer with n neurons\n","# and the sigmoid activation function\n","model.add(Dense(3, activation='sigmoid'))\n","\n","# Then add the output layer with 1 neuron\n","# and a linear activation function\n","model.add(Dense(1))\n","\n","#model.build((None, 3))\n","model.summary()\n","print(model.count_params())\n","\n","opt = tf.optimizers.Adam(learning_rate=0.0005)\n","print(\"\")\n","print(\"Generating model ...\")\n","# fix random seed for reproducibility\n","seed = 1\n","xtrain_for_parameter_fitting, x_validation, ytrain_for_parameter_fitting, y_validation = train_test_split(xtrain, ytrain, test_size=0.3, random_state=seed)\n","\n","model.compile(loss='mse', optimizer=opt, metrics=['mean_squared_error'])\n","#history = model.fit(x=xtrain,y=ytrain, epochs=200, validation_split=0.3, verbose=0)\n","history = model.fit(x=xtrain_for_parameter_fitting,y=ytrain_for_parameter_fitting, epochs=200, validation_data=(x_validation,y_validation), verbose=0)\n","\n","\n","print(\"Model generation completed\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p1WX1hmxZYp4","executionInfo":{"status":"aborted","timestamp":1652109510673,"user_tz":300,"elapsed":10,"user":{"displayName":"Diego Azuela","userId":"18307101454027383455"}}},"outputs":[],"source":["loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","print(\"Final loss value in training set: \", loss[-1])\n","print(\"Final loss value in validation set: \", val_loss[-1])\n","\n","# Plot learning curve\n","plt.plot(history.history['loss'], label='Loss (training data)')\n","plt.plot(history.history['val_loss'], label='Loss (validation data)')\n","plt.title('Learning curve')\n","plt.ylabel('Loss')\n","plt.xlabel('No. epoch')\n","plt.legend(loc=\"upper right\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fDSigMBHwSIZ"},"outputs":[],"source":["# Use the model to calculate predictions for the train set\n","y_pred = model.predict(xtrain_for_parameter_fitting)\n","y_pred_df = pd.DataFrame(y_pred)\n","y_pred_df.columns =['y'] \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ssoUl6uxa4W"},"outputs":[],"source":["# Scale back the predictions and original values\n","y_pred_rescaled = scale_back(pd.DataFrame(y_pred), ytrain_min, ytrain_range)\n","y_pred_rescaled.columns =['y'] \n","y_train_rescaled = scale_back(pd.DataFrame(ytrain_for_parameter_fitting), ytrain_min, ytrain_range)\n","y_train_rescaled.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qtlJJ_KyyNJ3"},"outputs":[],"source":["# r-squared\n","r2_squared = r2_score(y_train_rescaled, y_pred_rescaled)\n","print('R-squared score of the train set:', round(r2_squared,4))\n","\n","# mean squared error\n","mse = mean_squared_error(y_train_rescaled, y_pred_rescaled)\n","rmse = np.sqrt(mse)\n","print('Root mean squared error of the train set:', round(rmse,4))\n","\n","# AIC\n","# trainable_weights includes neuron weights and biases\n","param_num = model.count_params()\n","print(\"Total number of parameters: \", param_num)\n","no_data_points = xtrain_for_parameter_fitting.shape[0]\n","aic = no_data_points * np.log(mse) + 2*param_num\n","print(\"Akaike Information Criterion:\", round(aic, 4))\n","\n","# Corrected AIC\n","aic_corrected = aic + \\\n","                2*param_num*(param_num+1)/(no_data_points - param_num -1)\n","print(\"Corrected Akaike Information Criterion:\", round(aic_corrected, 4))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TvAjqXjyjf5A"},"outputs":[],"source":["# Use the model to calculate predictions for the test set\n","y_pred = model.predict(xtest)\n","\n","y_pred_df = pd.DataFrame(y_pred)\n","y_pred_df.columns = ['y'] \n","y_pred_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Is01nHa6-itv"},"outputs":[],"source":["# Scale back the predictions and original values for the test set\n","y_pred_rescaled = scale_back(pd.DataFrame(y_pred), ytest_min, ytest_range)\n","y_pred_rescaled.columns =['y'] \n","y_test_rescaled = scale_back(pd.DataFrame(ytest), ytest_min, ytest_range)\n","y_test_rescaled.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2jWoTdal-itx"},"outputs":[],"source":["# r-squared with test set\n","r2_squared = r2_score(y_test_rescaled, y_pred_rescaled)\n","print('R-squared score of the test set:', round(r2_squared,4))\n","\n","# mean squared error with the test set\n","mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n","rmse = np.sqrt(mse)\n","print('Root mean squared error of the test set:', round(rmse,4))\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyhcqmrL-itz"},"outputs":[],"source":["# Generate a scatter plot of predicted vs actual data\n","plt.figure(figsize=(5,5))\n","plt.scatter(x = y_test_rescaled, y = y_pred_rescaled)\n","plt.xlabel(\"'actual'\")\n","plt.ylabel(\"'predicted'\")\n","plt.title(\"Scatter plot of predicted vs actual data\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4wOdv7tr-it0"},"outputs":[],"source":["# Add a time column for plotting purposes\n","y_test_rescaled['time'] = y_test_rescaled.index\n","y_test_rescaled = y_test_rescaled.sort_values(by=['time'])\n","y_actual = pd.DataFrame(y_test_rescaled['y'])\n","y_actual.reset_index(drop=True, inplace=True)\n","\n","y_pred_rescaled['time'] = y_test_rescaled.index\n","y_pred_rescaled = y_pred_rescaled.sort_values(by=['time'])\n","y_hat = pd.DataFrame(y_pred_rescaled['y'])\n","y_hat.reset_index(drop=True, inplace=True)\n","\n","time = y_test_rescaled['time']\n","\n","# To export the predictions and test values to a CSV file\n","df.to_csv(r'Path where you want to store the exported CSV file\\File Name.csv', index = False)\n","y_test_rescaled.to_csv(r'ytest.csv', index = False)\n","y_pred_rescaled.to_csv(r'yhat.csv', index = False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tS01B4Pr-it3"},"outputs":[],"source":["plt.figure(figsize=(20, 10))\n","plt.plot(time, y_actual, linestyle='solid', color='r')\n","plt.plot(time, y_hat, linestyle='dashed', color='b')\n","\n","plt.legend(['Actual','Predicted'], loc='best', prop={'size': 14})\n","plt.title('Actual vs Predicted values', weight='bold', fontsize=16)\n","#plt.ylabel('demand', weight='bold', fontsize=14)\n","#plt.xlabel('time', weight='bold', fontsize=14)\n","plt.xticks(weight='bold', fontsize=12, rotation=45)\n","plt.yticks(weight='bold', fontsize=12)\n","plt.grid(color = 'y', linewidth='0.5')\n","plt.show()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dT3yc8lUZYp6"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"to1RxbIlZYp6"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ann_time_series.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}